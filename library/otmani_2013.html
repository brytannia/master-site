<!DOCTYPE HTML>
<!--
	TXT 2.5 by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Линда Отмани, Абделькадер Беньету — Нейронные байесовские сети в применении к распознаванию речи (перевод Т. Брынза)</title>
		<meta http-equiv="content-type" content="text/html; charset=utf-8" />
		<link href="http://fonts.googleapis.com/css?family=PT+Sans:400,700" rel="stylesheet" />
		<script src="../js/config_sub.js"></script>
		<script src="../js/skel.min.js"></script>
		<noscript>
			<link rel="stylesheet" href="../css/skel-noscript.css" />
			<link rel="stylesheet" href="../css/style.css" />
			<link rel="stylesheet" href="../css/style-desktop.css" />
		</noscript>
	</head>
	<body class="homepage">
	<div class="index">
			<a href="index.html" class="index">Назад в библиотеку</a>
	</div>

		
		
		
		<!-- Main -->
			<div id="main-wrapper" style="border-top-width: 0px">
				<div id="main" class="container">
					<div class="row">
						<div class="12u">

							<!-- Features -->
								<section class="is-features">
									<h3 class="major"><span>Нейронные байесовские сети в применении к распознаванию речи</h3>
									<article class="header">
														<span class="titler">Авторы: </span><span>Линда Отмани, Абделькадер Беньету</br><span class="titler">Перевод: </span><span>Татьяна Брынза</br>
														<span class="titler">Источник: </span>Linda OTMANI et Abdelkader BENYETTOU Les réseaux neuro-bayésiens appliqués à la reconnaissance de la parole. International Conference on Electrical Engineering and Automatic Control 2013 </span>
									</article>
									<div>
										
										<section>
											<h3>Резюме</h3>
											<p>Машинное распознавание речи является важным объектом научных исследований уже на протяжении пятидесяти лет. Не смотря на достигнутый за последние годы значительный прогресс в этой области, качество разработанных систем распознавания речи все еще далеко от того, что умеет человек. Распознавание и понимание речи является важнейшей проблемой распознавания образов и искусственного интеллекта, и для ее решения разработаны многочисленные методы – оригинальные или адаптированные.</p><p>
Среди большого количества моделей, предлагаемых для решения проблемы распознавания речи, имеются нейронные сети, занимающие в течении последних  десяти лет заметное место среди инструменов для решения сложных задач классификации и распознавания образов,   которые в точности находим в распознавании речи.
</p>
											<p>
											В этой статье мы протестируем новую методику распознавания речи, основанную на использовании нейронной сети как модели распознавания и байесовских методов для обучения этой модели. </br>
Ключевые слова: Байесовские методы, нейронная сеть, метод Монте Карло, контрольная выборка, TIMIT, метод обратного распространения ошибки, распознавание речи, распределение Гаусса.
</p>
														<h3 class="article">Введение</h3>
														<p>Байесовские методы применялись в последние годы к нейронным сетям разными авторами, в частности в работах МакКея (1992 а, б), Нила (1992, 1994, 1996), Бунтин и Вейдженеда (1991), Бишопа (1995), и наиболее новых работах Фрейта (1998, 2000) и Ветари (1999).
Вейдженед, Нил и МакКей показали, что байесовские методы для обучения нейронных сетей могут принести многочисленные преимущества, так как не требуется ограничивать размер сети чтобы избежать переобучения; количество нейронов в скрытом слое может достигать бесконечности; единственный фактор, который может ограничить размер сети – это возможности используемых компьютеров и имеющееся время для выполнения требуемых расчетов. Так как используемые параметры для расчета требуемых интегралов происходят из вероятностной выборки, то чтобы узнать требуемые параметры, необходимо вмешаться в распределения других параметров. </p><p>
В целом, невозможно рассчитать эти интегралы аналитически, и многочисленные подходы были предложены для выполнения их расчетов. Но либо эти подходы очень сложно применить, либо они используют аппроксимацию, которая может исказить результаты.</p><p>
В своей работе в 1994 Нил использует методы Монте Карло в связке с скрытыми Марковскими моделями для вычисления требуемых на разных этапах интегралов. Эти вычисления очень сложные и требуют много времени.</p><p>
МакКей предложил аппроксимацию, базирующуюся на гауссовых гипотезах о апостериорных вероятностях. Благодаря этим гипотезам, вычисление интегралов упрощается и может быть выполнено более или менее просто. Эти гипотезы иногда бывают спорными, в частности для задачи классификации. Тем не менее, благодаря этим аппроксимациям, вычисления упрощаются настолько, что байесовский подход становится употребим на практике.</p><p>
В этой статье мы собираемся интегрировать в байесовских методах для расчета разных интегралов выборку по значению, которая является техникой Монте Карло.
</p>
<h3 class="article">1.	Обучения байесовскими методами</h3>
<p>Использование теоремы Байеса позволяет предложить байесовскую формулировку обучения, которая является наиболее общей и которая может быть применима к исследованиям любых типов моделей, если только они представляются множеством параметров по которым можно сделать предположение о распределении. Мы описываем здесь принцип интуитивного подхода, и также показываем его применение в рамках нейронных сетей. </p><p>
Пусть X будет набором переменных. Пусть D будет базой примеров, объединяющей наблюдения и эти переменные. Мы ищем способ придать вес этим наблюдением с помощью модели M, выбирая из семьи моделей М. Единожды выбранная, эта модель будет предсказывать будущие наблюдения.</p><p>
Чтобы использовать байесовское обучение в этой проблеме, достаточно остановиться на том, что мы ищем приближение моделью m распределения вероятности P(X). Оно не ограничивается общим подходом, так как в детерминированной модели классификации предсказание может быть описано распределением частных вероятностей.</p><p>
Также предположим,  что запись P(M,D) имеет смысл. Другими словами, говоря, что модель М может быть представлена параметрами, и что мы может определить распределение вероятностей по этим параметрам (для модели нейронных сетей параметры будут весами сети).</p><p>
По определению условной вероятности, имеем:
<article class="picture">
															<img src="images/art10pic1.gif" alt="probabilite">
														</article>
В применении к теореме Байеса:
<article class="picture">
															<img src="images/art10pic2.gif" alt="app Bayes">
														</article>
Для множества примеров и априорного распределения Р(М) дано, Р(D) тогда является независимой от М константой.
Из этого следует что P является фундаментальной формулировкой байесовского обучения и тогда можно сказать, что:
Апостериорная = априорная вероятность.
</p>
<h3 class="article">2. Байесовские методы обучения нейронных сетей</h3>
<p>Классическое обучение эффективно в нахождении вектора весов, который минимизирует функцию издержек или ошибки.</p><p>
В байесовских методах, все параметры, особенно веса сети, рассматриваются как случайные величины распределения вероятностей.</p><p>
Обучение нейронной сети в таком случае состоит из определения распределения вероятностей весов для обучающей выборки: присваиваем весам фиксированные априорные вероятности, и сразу же, когда данные для обучения становятся видимыми, эта априорная вероятность трансформируется в апостериорную вероятность благодаря теореме Байеса.
Так как если D представляет обучающее можество, р(w) это удельный весс  априорной вероятности весов , р(D|w) – удельный вес вероятности наблюдения известных значений весов сети и Р(w|D) – апостериорная вероятность того, что ищем определенное значение. Итак,  теорема Байеса гласит:
<article class="picture">
															<img src="images/art10pic3.gif" alt="apriori">
														</article>
Для того чтобы упростить обучение нейронных сетей байесовскими методами мы собираемся использовать последовательное обучение.
</p>
<h3 class="article">3. Последовательное обучение нейронных сетей.</h3>
<p>Чтобы выполнить последовательное обучение, предположим, что эволюция нейронной сети во времени будет представлена двумя уравнениями, первое описывает изменение весов в сети, второе описывает нелинейное отношение входов к выходам:
<article class="picture">
															<img src="images/art10pic4.gif" alt="weights">
														</article>

Где y является переменной выхода, x – переменной входа, и w описывает весы нейронной сети.</p><p>
Надо учитывать, что при последовательном моделировании методом Монте-Карло переменные искажены шумом v, распределение вероятности шума определяется пользователем.
В нашем случаее, шум моделируется гауссовским распределением со средним ноль и ковариантностью R. Шум переменных не кореллируется с весами сети и начальными условиями. (Фрета 1998, Гордон 1993)</p><p>
Мы предполагаем, что изменение весов сети зависит от их предыдущих значений и стохастической составляющей d(k). Эта составляющая симулируется гауссовским распределением со средним нулем и ковариантным Q, однако, другие распределения также могут быть использованы.</p><p>
Сейчас теорема Байеса в формулировке (1) может быть записанна как (4)

<article class="picture">
															<img src="images/art10pic5.gif" alt="prob">
														</article>
Целью является найти текущее состояние системы V зная значения Y, которые определяют плотность распределения вероятностей р (W/Y) где Y = {y1, y2 … yk} и  W = {w1, w2 … wk}.
р (W/Y) является решением проблемы. Но интересно оценить однby из этих пределов, названный плотностью фильтрации р(w/Y).  Если бы мы знали эту плотность, можно просто расчитать веса сети (Фрета 1998) С Р(w/Y) функция плотности постериорного распределения, р(y/w) плотность вероятности и р(w/Y) соотносится с функцией плотности априорной вероятности. </p><p>
Формула (4) отвечает оптимальному решению проблемы, но к сожалению, она привносит многомерное интегрирование (так как используемые параметры происходят из распределения вероятностей, для того чтобы узнать параметр расчета интегралов требуется вмешаться в распределения других параметров). Это интегрирование является источником большей части практических сложностей. В большинстве применений, аналитическое решение невозможно, поэтому мы должны прибегнуть к другим методикам, таким, чтобы гауссово приближение (МакКэй 1999) и методы Монте Карло (Бишоп 1995, Фрета 1998, Нил 1996), в нашем случае позволили использовать выборку по значимости для расчета разных интегралов.

</p>
<h3 class="article">4. Выборка по значимости</h3>
<p>Большинство подходов могут быть использованы для увеличения эффективности методов Монте Карло. Среди них существует техника выборки по значимости, являющейся наиболее удобной и наиболее эффективной по сравнению с другими техникой уменьшения дисперсии. (Фрета 1998, Гулль 1988, Мюллер 1991).
Можно сказать, что эта техника является эффективным инструментом для вычисления вероятностных событий, ради которого мы и применяем байесовские методы для обучения нейронных сетей.</p><p>
Фундаментальная идея, заложенная в методах Монте Карло, заключается в том, что вместе взятые взвешенные образцы из функции постериорной плотности весов нейронной сети используются для отслеживания интегрирования, включенного в процесс интерференции дискретных сумм. (рис. 1). Мы используем следущее приближение Монте Карло:
<article class="picture">
															<img src="images/art10pic6.gif" alt="aproximation Monte Carlo">
														</article>

Где Wк представляет образцы используемые для описания постериорной плотности, S количество образцов и δ описывает дельта-функцию Дирака и индекс к представляет время.
Техники выборки по значимости Монте Карло являются числовой дискретной апроксимацией в том плане, что они автоматически выбирают образцы в областях высокой вероятности. (рис 1) (Мюллер 1991, Мюллер 1992).
<article class="picture">
															<img src="images/art10pic7.gif" alt="echantillonage">
															<span></br>Рисунок 1 – Процесс выборки Монте Карло</span>
														</article>

Это означает, что любая функция f из Wk может быть записана в форме 
<article class="picture">
															<img src="images/art10pic8.gif" alt="function f by W">
														</article>

Так как S (количество образцов) стремится к бесконечности, апроксимация стремится к равновесию.</p><p>
В случае методов Монте Карло, веса взяты из функции плотности вероятности р(Wk/Yk), но достижение базовой вероятности ведет нас к увеличению числа образцов S, которые будут очень дорогими по фактору времени. Тем не менее, можно преодолеть эту трудность техникой выборки по значимости. Она позволяет нам взять веса функции модифицированной плотности π(Wk/Yk) и ассоциировать с каждым образцом значение (q) называемое пропорцией важности, такой что: (Ветари 1998, Ветари 2000).
<article class="picture">
															<img src="images/art10pic9.gif" alt="proportion important">
														</article>


Теперь с помощью техники выборки по значимости, мы может взять образцы Wk(1) из предложенной функции π (Рубинштейн 1981).</p><p>
Для того чтобы вычислить последовательно оценку функции плотности π (за время k) без модификации симулируемых предыдущих состояний (Wk-1), мы применяем функцию плотности: 

<article class="picture">
															<img src="images/art10pic10.gif" alt="function of density">
														</article>

На этом этапе нам необходимо вспомнить что вычисление весов соответствует марковскому процессу и что наблюдатели независимы:

<article class="picture">
															<img src="images/art10pic11.gif" alt="Markov observation">
														</article>

Таким образом пропорция важности рекурсивно и последовательно получается из формулы 

<article class="picture">
															<img src="images/art10pic12.gif" alt="proportion of importance">
														</article>

чтобы избежать деградации метода выборки по значимости, используется этап пересемплирования чтобы ликвидировать образцы которые имеют базовую пропорцию важности, и увеличить образцы с высокой пропорцией важности.</p><p>
Чтобы реализовать этап пересемплирования, вместе определяем: Образец с наибольшим выбранным значением q.</p><p>
Использование результата Конга (Конг 1994), который требует чтобы ресемплирование было выполнено только если размер эффективной выборки Nef f был выше фиксированного порога.
Размер эффективной выборки определен как:
<article class="picture">
															<img src="images/art10pic13.gif" alt="effective echantillon">
														</article>

Здесь мы должны объяснить как вычислить пропорции последовательной важности и как улучшить набор образцов в перевыборке.</p><p>
Сейчас мы применяем следующую функцию плотности вероятности:

<article class="picture">
															<img src="images/art10pic14.gif" alt="funk of density">
														</article>

Так как выбор функции плотности π(.) это одна из критических точек в последовательном алгоритме выборки по значимости. Дусе (Дусе 2000) показал что функция:
<article class="picture">
															<img src="images/art10pic15.gif" alt="pi">
														</article>


Минимизирует дисперсию пропорции важности в Wk и Yk.</p><p>
Этот выбор функции обоснован и другими исследователями. Однако, плотность:

<article class="picture">
															<img src="images/art10pic16.gif" alt="density">
														</article>
является наиболее известной функцией. Она более оптимальна чем уравнение (13)</p><p>
Сейчас, можем выбрать начальные веса и пропорции важности Приора с:
<article class="picture">
															<img src="images/art10pic17.gif" alt="importance of Prior">
														</article>
И для каждого этапа выборки предсказывать новые веса (уравнение 2), вычислять новые пропорции важности (ур 11, 12, 14) и делать перевыборку, если требуется.
</p>
<h3 class="article">5. Приложение к распознаванию речи</h3>
<p>Для валидации этой техники на распознавании речи, используем американскую базу данных ТИМИТ, которая является известной базой для обеспечения фонетическими акустическими данными речи для разработки и обучения автоматической системы распознавания речи.</p><p>
Она содержит записи 630 америанских дикторов, разделенных на 8 «региональных диалектов» («рд1», «рд2») и говорящий каждый по 10 фраз. (Лоншап 1991а, 1991б).</p><p>
5.1 Использованный корпус</p><p>
Наши тести были выполнены на 18 фонемах выбраных из базы данных ТИМИТ: 6 фрикативов, 6 гласных и 6 взрывных звуков.</p><p>
Система предоставляет важное количество для обработки:</br>
- Каждая фонема встречается во фразе 2 раза (один раз для обучения и другой для теста)</br>
- Формат хранения данных (дабл с плавающей точкой, 32 бита)</p>
<article class="picture">
															<img src="images/art10pic18.gif" alt="params of experiment">
														</article>
<p>
5.2 Архитектура использованной нейронной сети </p><p>
Для валидации нашей техники, выбрали многослойную нейронную сети (МЛП) как модель распознавания, за их общеизвестную способность быть хорошим всеобщим апроксиматором и классификатором. </p><p>
Мы тренировали нейронную сеть на разных архитектурах, и с разными параметрами чтобы найти лучшую модель, которая нам даст максимальную плотность постериорной вероятности весов и ее, согласно принципу максимума апостериор (МАР). Принимаем следующие предположения:</p><p>
- Веса</p><p>
Начальные значения весов сети выбраны из функции плотности гауссовой вероятности …
Для двух распределений берем среднее ноль и дисперсию 1 (элементы диагонали матрицы начальных весов).</p><p>
- Шум</p><p>
Предполагаем что шум в симулируется гауссовым распределением со средним нулем и R = 0,7 (элементы диагонали ковариационной матрицы), подобно тому как d симулируется гауссовым распределением со средним нулем и ковариантностью равной q.</p><p>
- Образцы</p><p>
Выбрали n=500 образцов для симуляции Монте Карло и для 100 итераций и k=200.</p><p>
5.3 Интерпретация результатов.</p><p>
Чтобы иметь возможность протестировать эффективность нашей техники обучения, сравним ее с наиболее классическим алгоритмом обучения нейронных сетей, алгоритмом «обратного распространения ошибки».</p><p>
Принимаем во внимание три ключевых фактора успеха в неважно каком процессе обучения: время обучения, процент распознавания, минимизация ошибки.</p><p>
Следуем следующим сокращениям: N1 – число нейронов во входном слое, N2 – число нейронов в скрытом слое, N3 – число нейронов в выходном слое.</p><p>
- Обучение</p>
Обучение производится двумя тестами с условиями остановки:</br>
- достижение максимального числа итераций</br>
- достижение минимальной ошибки.</br>
<p>Хотим исправить параметры сети (архитектуры N1=128, N2=64, N3=18, максимальное число итераций и ошибка заданы) чтобы иметь возможность сравнить результаты двух методов:
Мы обучили сеть и записали результаты в рис. 2:</p>
<article class="picture">
															<img src="images/art10pic19.gif" alt="results">
															<span></br>Рисунок 2 – Сравнение среди реализованного числа итераций</span>
														</article>
<p>Рис2 иллюстрирует эффективность обучения байесовскими методиками, ожидающие фиксированную минимальную ошибку и максимум своего процента распознавания (75,4%) без исчерпания максимального числа итераций, наоборот, обучение методом обратного распространения ошибки израсходовало все (или почти) число итераций чтобы добиться требуемого значения ошибки и как результат процент ошибки, соответствующий (71,2%)</p><p>
Процент прспознавания</p>
<article class="picture">
															<img src="images/art10pic19.gif" alt="results">
															<span></br>Таблица 2 – Средний процент распознавания фонем</span>
														</article>
<p>Для (архитектуры N1=128, N2=64, N33=18, q =0,1) можем получить максимальный процент обучения и можем ожидать желаемую минимальную ошибку.</p><p>
Отметим также, что так как число нейронов скрытого слоя увеличиваеся и это улучшает требуемый результаты для обучения или распознавания, тогда как с такой же архитектурой, которая нам дает относительно хорошие результаты с байесовским распознаванием, мы имеем одинаковый результат среди обучение градиентом.</p><p>
В таблице 2 представлены результаты, полученные при распознавания 18 фонем и баейсовскими методами и алгоритмом обратного распространения ошибки. На сотой иттерации, мы получили среднее распознавание равное 57.6% для обратного распостранения ошибки и 62.0% для байесовских методов (128, 64, 18).</p><p>
Ошибка</p><p>
Зафиксировано уменьшение ошибки при обучении байесовскими методами по сравнению с ошибкой, полученной при обучении обратным градиентом.
</p>
<h3 class="article">6. Выводы</h3><p>
В этой статье представлены техники обучения нейронных сетей, основанные на принципе методов монте-карло и выборке по значимости. Применяю последнюю в байесовским методам для вычисления интегралов на разных этапах обучения нейронной сети мы получили результаты, которые превосходят результаты обучения с помощью найболее классического алгоритма обратного распостранения ошибки.</p><p>
Применение этого алгоритма к распознаванию речи четко показывает, что данная техники обучения представляет интересную и многообещающую альтернативу существующим методам. Техника выборки предоставляет лучшее описание распределения вероятностей весов сети чем классические методы.</p><p>
Мы получили пользу из главного качества выборки по значимости, которым является уменьшение времени вычислений, для улучшения метода монте карло и как следствие минимизания времени обучения нейронной сети. </p><p>
Можем констатировать также увеличение коэффициента распознавания, а следовательно и уменьшения ошибки классификации фонем, зная что неопределенность весов принята во внимание для корректировки вычисленной вероятности сетью для задачи классификации.
Хотя проблема автоматического распознавания речи сложная, мы можем улучшить показатели на 10% перейдя от алгоритмов обратного распостранения ошибки к байесовским методам для обучения нейронной сети, используя выборки по значимости.</p>

<h3 class="article">Литература</h3>
<p>
1.	D. J. C. MacKay. “Bayesian interpolation”.  Neural 
Computation, 4(3), 415-447, 1992 a.
</br>
2.	D. J. C. MacKay. “A Practical Bayesian Framework 
for  Backpropagation  Networks”.  Neural  Computation, 
4(3), 448-472, 1992 b. 
</br>
3.	R.  M.  Neal.  “Bayesian  Training  of  Backpropagation 
Networks  by  the  Hybrid  Monte  Carlo  Method”. 
Technical  Report  CRG-TR-92-1,  Department  of 
Computer Science, University of Toronto, 1992. 

</br>
4.	W.  Buntine,  A.S  “Weigend.Bayesian  backpropagation“. Complex Systems, 5, 603-643, 1991.
</br>
5.	C.  M.  Bishop.  “Neural  Networks  for  Pattern 
Recognition”. Clarendon Press, Oxford, 1995. 
</br>
6.	JFG de Freitas, M Niranjan, A H Gee, and A Doucet. 
</br>
7.	“Sequential  Monte  Carlo  methods  for  optimisation  of neural  network  models”.  Technical  Report  CUED/FINFENG/TR  328,  Cambridge  University  Engineering 
</br>
8.	Aki Vehtari et Jouko Lampinen. « Bayesian neural 
networks  with  correlating  residuals”.  In  Proc. 
IJCNN’99, Washington, DC, USA, July 1999. 
</br>
9.	JFG  de  Freitas.  “Robust  full  bayesian  methods  for 
neural network”, Cambridge university , 2000. 
</br>
10.	Philippe  Leray  et  Olivier  François,  « Etude 
comparative  d’algorithme  d’apprentissage  et  de 
structure  dans  les  réseaux  bayésiens »,  Laboratoire 
Perception, Systèmes, Information — FRE CNRS 2645. 
</br>
11.	S.Richardson.Méthodes  “bayésiennes  en 
modelisation  spatiale”,  département  of  epidemiilogy 
and public health, imperial college, London.  
</p>
													</section>
												<!-- /Feature -->
										
									</div>
								</section>
							<!-- /Features -->

						</div>
					</div>
					
					</div>
				</div>
			</div>
		<!-- /Main -->

		<!-- Footer -->
			<footer id="footer" class="container">
				
				<!-- Links -->

					<div > 
					<span>
						<a href="http://donntu.edu.ua/index.php?lang=ru">Официальный сайт ДонНТУ</a> | 
						<a href="http://masters.donntu.edu.ua/index.htm">Портал магистров ДонНТУ</a> 
					</div>

				<!-- /Links>
				
				
				<!-- Copyright -->
					<div id="copyright">
						&copy; Татьяна Брынза | Дизайн: <a href="http://html5up.net/">HTML5 UP</a>
					</div>
				<!-- /Copyright -->

			</footer>
		<!-- /Footer -->

	</body>
</html>